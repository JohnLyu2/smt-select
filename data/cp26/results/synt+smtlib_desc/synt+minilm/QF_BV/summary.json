{
  "division": "QF_BV",
  "n_seeds": 5,
  "seed_values": [
    0,
    10,
    20,
    30,
    40
  ],
  "model_type": "SVM",
  "splits_dir": "/home/john-lu/Desktop/smt-select/data/cp26/performance_splits/smtcomp24/QF_BV",
  "feature_csv_path": [
    "data/features/syntactic/catalog_all/QF_BV.csv",
    "data/features/smtlib_desc/minilm/QF_BV.csv"
  ],
  "seeds": [
    {
      "seed": 0,
      "train_size": 8027,
      "test_size": 2676,
      "train_metrics": {
        "solved": 7915,
        "avg_par2": 44.72160113420482,
        "sbs_name": "Bitwuzla",
        "sbs_solved": 7864,
        "sbs_avg_par2": 61.77599266787249,
        "vbs_solved": 7918,
        "vbs_avg_par2": 41.85153200714887,
        "gap_cls_solved": 0.9444444444444444,
        "gap_cls_par2": 0.8559524809264416
      },
      "test_metrics": {
        "solved": 2635,
        "avg_par2": 48.58768615373074,
        "sbs_name": "Bitwuzla",
        "sbs_solved": 2625,
        "sbs_avg_par2": 58.10378827141716,
        "vbs_solved": 2642,
        "vbs_avg_par2": 40.25809746050704,
        "gap_cls_solved": 0.5882352941176471,
        "gap_cls_par2": 0.5332436955519066
      }
    },
    {
      "seed": 10,
      "train_size": 8027,
      "test_size": 2676,
      "train_metrics": {
        "solved": 7909,
        "avg_par2": 46.90363074661768,
        "sbs_name": "Bitwuzla",
        "sbs_solved": 7865,
        "sbs_avg_par2": 61.78417641632123,
        "vbs_solved": 7914,
        "vbs_avg_par2": 43.20045916735318,
        "gap_cls_solved": 0.8979591836734694,
        "gap_cls_par2": 0.8007303097839515
      },
      "test_metrics": {
        "solved": 2639,
        "avg_par2": 43.60406006885339,
        "sbs_name": "STP",
        "sbs_solved": 2627,
        "sbs_avg_par2": 57.66332678096884,
        "vbs_solved": 2646,
        "vbs_avg_par2": 36.211820063287306,
        "gap_cls_solved": 0.631578947368421,
        "gap_cls_par2": 0.6553976323037025
      }
    },
    {
      "seed": 20,
      "train_size": 8027,
      "test_size": 2676,
      "train_metrics": {
        "solved": 7916,
        "avg_par2": 44.14822607915324,
        "sbs_name": "Bitwuzla",
        "sbs_solved": 7865,
        "sbs_avg_par2": 60.975859810918074,
        "vbs_solved": 7921,
        "vbs_avg_par2": 40.68144053542927,
        "gap_cls_solved": 0.9107142857142857,
        "gap_cls_par2": 0.8291754251913438
      },
      "test_metrics": {
        "solved": 2634,
        "avg_par2": 49.65029753118718,
        "sbs_name": "Bitwuzla",
        "sbs_solved": 2624,
        "sbs_avg_par2": 60.50388783897062,
        "vbs_solved": 2639,
        "vbs_avg_par2": 43.76793462175265,
        "gap_cls_solved": 0.6666666666666666,
        "gap_cls_par2": 0.6485193981432295
      }
    },
    {
      "seed": 30,
      "train_size": 8027,
      "test_size": 2676,
      "train_metrics": {
        "solved": 7923,
        "avg_par2": 42.42852316428494,
        "sbs_name": "Bitwuzla",
        "sbs_solved": 7870,
        "sbs_avg_par2": 59.73287903806865,
        "vbs_solved": 7928,
        "vbs_avg_par2": 38.991442906889496,
        "gap_cls_solved": 0.9137931034482759,
        "gap_cls_par2": 0.8342891863582811
      },
      "test_metrics": {
        "solved": 2626,
        "avg_par2": 56.69090091430463,
        "sbs_name": "Bitwuzla",
        "sbs_solved": 2619,
        "sbs_avg_par2": 64.2323656654513,
        "vbs_solved": 2632,
        "vbs_avg_par2": 48.837295968646785,
        "gap_cls_solved": 0.5384615384615384,
        "gap_cls_par2": 0.4898623325305256
      }
    },
    {
      "seed": 40,
      "train_size": 8027,
      "test_size": 2676,
      "train_metrics": {
        "solved": 7920,
        "avg_par2": 42.93187634095911,
        "sbs_name": "Bitwuzla",
        "sbs_solved": 7868,
        "sbs_avg_par2": 59.7629644565803,
        "vbs_solved": 7924,
        "vbs_avg_par2": 40.0005839586007,
        "gap_cls_solved": 0.9285714285714286,
        "gap_cls_par2": 0.8516731128287867
      },
      "test_metrics": {
        "solved": 2631,
        "avg_par2": 53.82178742930527,
        "sbs_name": "Bitwuzla",
        "sbs_solved": 2621,
        "sbs_avg_par2": 64.14212065259892,
        "vbs_solved": 2636,
        "vbs_avg_par2": 45.810249921529525,
        "gap_cls_solved": 0.6666666666666666,
        "gap_cls_par2": 0.5629721796915383
      }
    }
  ],
  "aggregated": {
    "train": {
      "gap_cls_solved_mean": 0.9190964891703807,
      "gap_cls_solved_std": 0.015984156104067664,
      "gap_cls_par2_mean": 0.8343641030177608,
      "gap_cls_par2_std": 0.01961540169740635
    },
    "test": {
      "gap_cls_solved_mean": 0.6183218226561878,
      "gap_cls_solved_std": 0.04926066063621428,
      "gap_cls_par2_mean": 0.5779990476441805,
      "gap_cls_par2_std": 0.0647465668498354
    }
  }
}